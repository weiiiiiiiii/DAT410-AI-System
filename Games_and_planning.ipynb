{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Games_and_planning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jln3oCnmlU7k"
      },
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "#Creating an Artificial Neural Network class\n",
        "\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, x, y, value):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.value = value\n",
        "        \n",
        "    def __repr__(self):\n",
        "        return \"x:{0} y:{1} v:{2}\".format(self.x, self.y, self.value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bInnWicVlbC1"
      },
      "source": [
        "#define the gameboard\n",
        "class gameboard:\n",
        "    x = 1  #differentiate the two player\n",
        "    o = -1\n",
        "    def __init__(self, state, next_move=1):\n",
        "        self.board = state\n",
        "        self.board_size = state.shape[0] #0 means place still available\n",
        "        self.next_move = next_move\n",
        "        \n",
        "    def result(self):\n",
        "        row_sum = np.sum(self.board, 0)\n",
        "        col_sum = np.sum(self.board, 1)\n",
        "        diag_sum1 = self.board.trace()\n",
        "        diag_sum2 = self.board[::-1].trace()\n",
        "        \n",
        "        s1 = any(row_sum == self.board_size) #different situation\n",
        "        s2 = any(col_sum == self.board_size)\n",
        "        s3 = (diag_sum1 == self.board_size)\n",
        "        s4 = (diag_sum2 == self.board_size)\n",
        "        \n",
        "\n",
        "        if s1 or s2 or s3 or s4:\n",
        "            return self.x\n",
        "        \n",
        "        s1 = any(row_sum == -self.board_size)\n",
        "        s2 = any(col_sum == -self.board_size)\n",
        "        s3 = (diag_sum1 == -self.board_size)\n",
        "        s4 = (diag_sum2 == -self.board_size)\n",
        "        \n",
        "\n",
        "        if s1 or s2 or s3 or s4:\n",
        "            return self.o\n",
        "        if np.all(self.board != 0):\n",
        "            return 0\n",
        "        return None\n",
        "       \n",
        "    \n",
        "    def game_over(self):\n",
        "        return self.result() is not None\n",
        "    \n",
        "    \n",
        "    def game_continue(self, move):\n",
        "        # If it is not the current players turn, can not move\n",
        "        if move.value != self.next_move:\n",
        "            return False\n",
        "        \n",
        "        # If move is outside of board, can not move\n",
        "        if ((not (0 <= move.x < self.board_size)) or\n",
        "            (not (0 <= move.y < self.board_size))):\n",
        "            return False\n",
        "        \n",
        "        # If (x, y) is not occupied, ok, otherwise not.\n",
        "        return self.board[move.x, move.y] == 0\n",
        "        \n",
        "        \n",
        "    def move(self, move):\n",
        "        if not self.game_continue(move):\n",
        "            raise ValueError(format(move, self.board))\n",
        "\n",
        "        new_board = np.copy(self.board)\n",
        "        new_board[move.x, move.y] = move.value\n",
        "            \n",
        "        return gameboard(new_board, self.next_move*-1)\n",
        "        \n",
        "    def legal_actions(self):\n",
        "        indices = np.where(self.board == 0)\n",
        "        return [\n",
        "            NeuralNetwork(c[0], c[1], self.next_move)\n",
        "            for c in list(zip(indices[0], indices[1]))\n",
        "        ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkIJjs0NlkvS"
      },
      "source": [
        "#define the MCTS node\n",
        "\n",
        "\n",
        "class MCTSNode:\n",
        "    def __init__(self, state, parent=None):\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.children = []\n",
        "        self.results = defaultdict(int)\n",
        "        self.n_visits = 0\n",
        "        self._untried_actions = None\n",
        "        \n",
        "    def untried_actions(self):\n",
        "        if self._untried_actions is None:\n",
        "            self._untried_actions = self.state.legal_actions()\n",
        "        return self.state.legal_actions()\n",
        "    \n",
        "    def Q(self):\n",
        "        n_wins = self.results[self.parent.state.next_move]\n",
        "        n_losses = self.results[-1 * self.parent.state.next_move]\n",
        "        return n_wins - n_losses\n",
        "     \n",
        "    def N(self):\n",
        "        return self.n_visits\n",
        "    \n",
        "    def expand(self):\n",
        "        action = self.untried_actions().pop()\n",
        "        next_state = self.state.move(action)\n",
        "        child = MCTSNode(next_state, parent=self)\n",
        "        self.children.append(child)\n",
        "        return child\n",
        "    \n",
        "    def terminal_node(self):\n",
        "        return self.state.game_over()\n",
        "    \n",
        "    def roll_out(self):\n",
        "        current_rollout_state = self.state\n",
        "        while not current_rollout_state.game_over():\n",
        "            possible_moves = current_rollout_state.legal_actions()\n",
        "            action = self.rollout_policy(possible_moves)\n",
        "            current_rollout_state = current_rollout_state.move(action)\n",
        "        return current_rollout_state.result()\n",
        "            \n",
        "    \n",
        "    def backpropagate(self, result):\n",
        "        self.n_visits += 1\n",
        "        self.results[result] += 1\n",
        "        if self.parent:\n",
        "            self.parent.backpropagate(result)\n",
        "    \n",
        "    def is_fully_expanded(self):\n",
        "        return len(self.untried_actions()) == 0\n",
        "    \n",
        "    def best_child(self, c_param=1.4):\n",
        "        choices_weights = [\n",
        "            (c.Q() / c.N()) + c_param * np.sqrt((2*np.log(self.N()) / c.N()))\n",
        "            for c in self.children\n",
        "        ]\n",
        "        return self.children[np.argmax(choices_weights)]\n",
        "        \n",
        "    def rollout_policy(self, possible_moves):\n",
        "        return possible_moves[np.random.randint(len(possible_moves))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N2Y7hlAll9z"
      },
      "source": [
        "#implement the MCTS\n",
        "class MCTS:\n",
        "    def __init__(self, node):\n",
        "        self.root = node\n",
        "        \n",
        "    def best_action(self, n_simulations): \n",
        "        for _ in range(0, n_simulations):\n",
        "            v = self.tree_policy()\n",
        "            reward = v.roll_out()\n",
        "            v.backpropagate(reward)\n",
        "        \n",
        "        return self.root.best_child(c_param=0.)\n",
        "    \n",
        "    def tree_policy(self):\n",
        "        current_node = self.root\n",
        "        while not current_node.terminal_node():\n",
        "            if not current_node.is_fully_expanded():\n",
        "                return current_node.expand()\n",
        "            else:\n",
        "                current_node = current_node.best_child()\n",
        "        return current_node"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT0KVxZaltBl",
        "outputId": "09adacfa-bae3-4ab4-ed1e-8d92c4359ce0"
      },
      "source": [
        "#play the game\n",
        "\n",
        "#current_state = np.zeros((3,3))  #if we want to play with 3 by 3\n",
        "\n",
        "\n",
        "#if we want to play with 4 by 4\n",
        "current_state = np.zeros((4,4))\n",
        "\n",
        "next_move = 1 #set AI as 1\n",
        "print(\"AI: -1, Human:1, Available place;0\")\n",
        "current_board = gameboard(state = current_state, next_move=next_move)\n",
        "while not current_board.game_over():\n",
        "    if next_move == -1: #human move\n",
        "        while True:\n",
        "            user_input = input()\n",
        "            coords = user_input.strip().split(sep=\",\")\n",
        "            x = int(coords[0])\n",
        "            y = int(coords[1])\n",
        "            if current_board.game_continue(NeuralNetwork(x, y, next_move)):\n",
        "                current_state[x, y] = -1\n",
        "                current_board = gameboard(state = np.copy(current_state), next_move=-1*next_move)\n",
        "                break\n",
        "            else:\n",
        "                print(\"The place is NOT available!!!\") \n",
        "\n",
        "        print(\"User move:\")\n",
        "        print(current_state)\n",
        "            \n",
        "    else:\n",
        "        root = MCTSNode(state = current_board)\n",
        "        mcts = MCTS(root)\n",
        "        best_node = mcts.best_action(1000)\n",
        "        current_state = best_node.state.board\n",
        "        current_board = gameboard(state = np.copy(current_state), next_move=-1*next_move)\n",
        "   \n",
        "        print(\"AI move:\")\n",
        "        print(current_state)\n",
        "    next_move *= -1\n",
        "print(\"Game Over\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AI: -1, Human:1, Available place;0\n",
            "AI move:\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]]\n",
            "2,1\n",
            "User move:\n",
            "[[ 0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  1.]]\n",
            "AI move:\n",
            "[[ 0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.]\n",
            " [ 0.  0.  1.  1.]]\n",
            "2,3\n",
            "User move:\n",
            "[[ 0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.]\n",
            " [ 0. -1.  0. -1.]\n",
            " [ 0.  0.  1.  1.]]\n",
            "AI move:\n",
            "[[ 0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.]\n",
            " [ 0. -1.  0. -1.]\n",
            " [ 0.  1.  1.  1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}