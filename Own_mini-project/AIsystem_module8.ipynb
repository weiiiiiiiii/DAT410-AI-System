{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AIsystem_module8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QCymLA83klx",
        "outputId": "fc8af88a-499d-466b-e2de-093c32f98d84"
      },
      "source": [
        "#add GPU\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWhchNl54TMa"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVPoZ79g4UbB",
        "outputId": "2c3e5874-2d31-4f65-d7d4-4ad75ea1f4d7"
      },
      "source": [
        "text = open(\"sonnet.txt\", \"r\") #read the txt file\r\n",
        "text=text.read() # we get the dataset\r\n",
        "text=text.lower() #make all the letters into small letters to avoid repeating.\r\n",
        "len(text) #we have 100231 lines intotal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_wiY2tG4UgT"
      },
      "source": [
        "characters = sorted(list(set(text))) #sort all the letters\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-RJFOjW4Uik"
      },
      "source": [
        "#transfer the characters to numbers, make the text readable for the machine.\r\n",
        "\r\n",
        "char_to_num = {char:n for n, char in enumerate(characters)}\r\n",
        "num_to_char = {n:char for n, char in enumerate(characters)}\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsMaLu-z4UlB"
      },
      "source": [
        "#data preprocessing\r\n",
        "X = [] #training sequence\r\n",
        "Y = [] #target array\r\n",
        "length = len(text) \r\n",
        "seq_length = 100 #length of the character sequence that we need to consider before predicting a specific character\r\n",
        "for i in range(0, length-seq_length, 1):\r\n",
        "  sequence =text[i:i+seq_length]\r\n",
        "  label =text[i + seq_length]\r\n",
        "  X.append([char_to_n[char] for char in sequence])\r\n",
        "  Y.append(char_to_n[label])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y770u2Xu6OGh",
        "outputId": "65379dee-e533-43b8-a098-7a376fd878e4"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWMOm7jF82X3"
      },
      "source": [
        "X_data = np.reshape(X, (len(X), seq_length, 1))\r\n",
        "X_data = X_data / float(len(characters))\r\n",
        "Y_data = np_utils.to_categorical(Y)   #one-hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCpoAILj9DSK",
        "outputId": "dcde155f-5a6a-4726-b26d-09dcbf00da96"
      },
      "source": [
        "#define the model\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(LSTM(1000, input_shape=(X_modified.shape[1],X_modified.shape[2]), return_sequences=True))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(LSTM(1200)) #sometimes change the unit number\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(Dense(Y_modified.shape[1], activation='softmax'))\r\n",
        "model.summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fa700810750>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu5jmyOACmNe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFPdUCu7Cj4r"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1PQv9wn-WXF",
        "outputId": "40f3956c-abd4-447e-cfb6-06751171b856"
      },
      "source": [
        "model.fit(X_modified, Y_modified, epochs=50, batch_size=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.9608\n",
            "Epoch 2/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.9592\n",
            "Epoch 3/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.7191\n",
            "Epoch 4/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.9454\n",
            "Epoch 5/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.8904\n",
            "Epoch 6/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.7820\n",
            "Epoch 7/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.7144\n",
            "Epoch 8/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.6437\n",
            "Epoch 9/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.5502\n",
            "Epoch 10/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.4406\n",
            "Epoch 11/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.3627\n",
            "Epoch 12/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.3025\n",
            "Epoch 13/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.2483\n",
            "Epoch 14/50\n",
            "1002/1002 [==============================] - 175s 174ms/step - loss: 2.1961\n",
            "Epoch 15/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.1465\n",
            "Epoch 16/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 2.0989\n",
            "Epoch 17/50\n",
            "1002/1002 [==============================] - 175s 174ms/step - loss: 2.0540\n",
            "Epoch 18/50\n",
            "1002/1002 [==============================] - 175s 175ms/step - loss: 2.0130\n",
            "Epoch 19/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 1.9672\n",
            "Epoch 20/50\n",
            "1002/1002 [==============================] - 175s 174ms/step - loss: 1.9269\n",
            "Epoch 21/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 1.8852\n",
            "Epoch 22/50\n",
            "1002/1002 [==============================] - 175s 174ms/step - loss: 1.8399\n",
            "Epoch 23/50\n",
            "1002/1002 [==============================] - 175s 174ms/step - loss: 1.7926\n",
            "Epoch 24/50\n",
            "1002/1002 [==============================] - 175s 174ms/step - loss: 1.7407\n",
            "Epoch 25/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 1.6891\n",
            "Epoch 26/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 1.6394\n",
            "Epoch 27/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 1.5801\n",
            "Epoch 28/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 1.5218\n",
            "Epoch 29/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 1.4550\n",
            "Epoch 30/50\n",
            "1002/1002 [==============================] - 174s 173ms/step - loss: 1.3877\n",
            "Epoch 31/50\n",
            "1002/1002 [==============================] - 174s 173ms/step - loss: 1.3208\n",
            "Epoch 32/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 1.2437\n",
            "Epoch 33/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 1.1662\n",
            "Epoch 34/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 1.0861\n",
            "Epoch 35/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 1.0107\n",
            "Epoch 36/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 0.9350\n",
            "Epoch 37/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 0.8617\n",
            "Epoch 38/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 0.7945\n",
            "Epoch 39/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 0.7289\n",
            "Epoch 40/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 0.6696\n",
            "Epoch 41/50\n",
            "1002/1002 [==============================] - 175s 174ms/step - loss: 0.6204\n",
            "Epoch 42/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 0.5716\n",
            "Epoch 43/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 0.5245\n",
            "Epoch 44/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 0.4852\n",
            "Epoch 45/50\n",
            "1002/1002 [==============================] - 174s 174ms/step - loss: 0.4547\n",
            "Epoch 46/50\n",
            "1002/1002 [==============================] - 175s 174ms/step - loss: 0.4259\n",
            "Epoch 47/50\n",
            "1002/1002 [==============================] - 175s 174ms/step - loss: 0.3934\n",
            "Epoch 48/50\n",
            "1002/1002 [==============================] - 175s 174ms/step - loss: 0.3738\n",
            "Epoch 49/50\n",
            "1002/1002 [==============================] - 175s 174ms/step - loss: 0.3470\n",
            "Epoch 50/50\n",
            "1002/1002 [==============================] - 175s 174ms/step - loss: 0.3378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa700999b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ-GPh2v9D_o"
      },
      "source": [
        "seq_mapped = X[99]\r\n",
        "full_seq = [n_to_char[value] for value in seq_mapped]\r\n",
        "# generating characters\r\n",
        "for i in range(400):\r\n",
        "    x = np.reshape(seq_mapped,(1,len(seq_mapped), 1))\r\n",
        "    x = x / float(len(characters))\r\n",
        "\r\n",
        "    pred_index = np.argmax(model.predict(x, verbose=0))\r\n",
        "    seq = [n_to_char[value] for value in seq_mapped]\r\n",
        "    full_seq.append(n_to_char[pred_index])\r\n",
        "\r\n",
        "    seq_mapped.append(pred_index)\r\n",
        "    seqg_mapped = seq_mapped[1:len(seq_mapped)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "j101BL5f9EMJ",
        "outputId": "b09da3e9-d281-4fd7-d27b-3d5476ea5a21"
      },
      "source": [
        "#generation text\r\n",
        "txt=\"\"\r\n",
        "for char in full_seq:\r\n",
        "    txt = txt+char\r\n",
        "txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"but as the riper should by time decease,\\n  his tender heir might bear his memory:\\n  but thou, contra noooeepoe'toeooe uoe wore'\\n oeonefnne e te tnlepneno'o re nyeronoe'' matne'oinf ffat,troeeoe'tof prooee'oyn  nennet'  heoi tnoeune'tee annoofooonoonnnnn'o rfnnn'd tynonn'e n unnofo'e n rnnonc'nye  ui tnneo'enoereonoono'nve ereonno'' ta tnnep'e d ne ne ti tennnf ponoe'trne nfrnnn'' neonef    eroineo'enoiree''netne'peeno'ooefoe tse oiens'tnn unneu,onneunnnee'  ne tinee ornoen o rnneonoeooe poefen e n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgYFJCKK9EOo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}